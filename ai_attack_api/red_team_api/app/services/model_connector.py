import artkit.api as akfrom typing import Any, Optional, Dictdef create_model_connector(input_data: Any, is_target: bool = True, augment: bool = False, evaluator: bool = False):    """    Creates a model connector for the specified model based on input type and configuration.    Compatible with single-turn, multi-turn, and evaluator requests.    """    # Determine the prefix based on whether we are creating a target, augmentor, or evaluator model    if augment:  # Augmentor configuration        model_type = input_data.augmentor_model_type        model_id = input_data.augmentor_model_id        api_key_env = input_data.augmentor_api_key_env        url = input_data.augmentor_url        system_prompt = None  # Augmentor models don't have system prompts        use_cuda = False        chat_template_params = {}    elif evaluator:  # Evaluator configuration        model_type = input_data.evaluator_model_type        model_id = input_data.evaluator_model_id        api_key_env = input_data.evaluator_api_key_env        url = input_data.evaluator_url        system_prompt = None  # Evaluator models don't have system prompts        use_cuda = False        chat_template_params = {}    elif hasattr(input_data, 'chat_target_model_type'):  # MultiTurnRequest        model_type = input_data.chat_target_model_type if is_target else input_data.chat_adversary_model_type        model_id = input_data.chat_target_model_id if is_target else input_data.chat_adversary_model_id        api_key_env = input_data.chat_target_api_key_env if is_target else input_data.chat_adversary_api_key_env        url = input_data.chat_target_url if is_target else input_data.chat_adversary_url        system_prompt = getattr(input_data, 'chat_target_system_prompt', None) if is_target else getattr(input_data, 'chat_adversary_system_prompt', None)        chat_template_params = input_data.chat_template_params if is_target and hasattr(input_data, "chat_template_params") else {}        use_cuda = input_data.use_cuda if hasattr(input_data, "use_cuda") else False    else:  # SingleShotRequest        model_type = input_data.model_type        model_id = input_data.model_id        api_key_env = input_data.api_key_env        url = input_data.url        system_prompt = getattr(input_data, 'system_prompt', None)        use_cuda = input_data.use_cuda if hasattr(input_data, "use_cuda") else False        chat_template_params = input_data.chat_template_params if hasattr(input_data, "chat_template_params") else {}    # Construct the model connector based on the model type    if model_type == 'Ollama':        return ak.OLLAMAChatConnector(model_id=model_id, url=url)    elif model_type == 'HuggingFaceChat':        return ak.HuggingfaceChat(            model_id=model_id,            api_key_env=api_key_env,            system_prompt=system_prompt,  # This will be None if not defined, making it optional            chat_template_params=chat_template_params        )    elif model_type == 'HuggingFaceLocal':        return ak.HuggingfaceChatLocal(            model_id=model_id,            use_cuda=use_cuda        )    elif model_type == 'OpenAI':        return ak.OpenAIChat(            api_key_env=api_key_env,            model_id=model_id,            temperature=0        )    elif model_type == 'CustomAPIChat':        # Additional logic for specific configurations of CustomAPIChat        custom_connector_params = getattr(input_data, 'custom_connector_params', {})        mode = custom_connector_params.get("mode", "chat")        httpx_client_kwargs = custom_connector_params.get("httpx_client_kwargs", {"verify": False})                return ak.CustomAPIChatConnector(            url=url,            api_key=api_key_env,            mode=mode,            httpx_client_kwargs=httpx_client_kwargs        )    else:        raise ValueError(f"Unsupported model_type: {model_type}")